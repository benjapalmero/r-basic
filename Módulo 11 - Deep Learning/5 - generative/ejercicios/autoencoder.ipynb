{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/generative/autoencoder.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/generative/autoencoder.ipynb\">\n",
    "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow the tensorflow introduction to [autoencoders tutorial](https://www.tensorflow.org/tutorials/generative/autoencoder) and the [VAEs tutorial](https://www.tensorflow.org/tutorials/generative/cvae)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:23:24.991125Z",
     "iopub.status.busy": "2021-01-13T02:23:24.990418Z",
     "iopub.status.idle": "2021-01-13T02:23:32.633598Z",
     "shell.execute_reply": "2021-01-13T02:23:32.632908Z"
    },
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Load the dataset\n",
    "To start, you will train the basic autoencoder using the Fashon MNIST dataset. Each image in this dataset is 28x28 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:23:32.640293Z",
     "iopub.status.busy": "2021-01-13T02:23:32.639570Z",
     "iopub.status.idle": "2021-01-13T02:23:33.526761Z",
     "shell.execute_reply": "2021-01-13T02:23:33.526222Z"
    },
    "id": "YZm503-I_tji"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEdCXSwCoKok"
   },
   "source": [
    "##  Basic Autoencoder\n",
    "\n",
    "Define an autoencoder with two Dense layers: an `encoder`, which compresses the images into a `latent_dim` dimensional latent vector, and a `decoder`, that reconstructs the original image from the latent space.\n",
    "\n",
    "To define your model, use the [Keras Model Subclassing API](https://www.tensorflow.org/guide/keras/custom_layers_and_models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:23:33.534279Z",
     "iopub.status.busy": "2021-01-13T02:23:33.533559Z",
     "iopub.status.idle": "2021-01-13T02:23:35.310668Z",
     "shell.execute_reply": "2021-01-13T02:23:35.311200Z"
    },
    "id": "0MUxidpyChjX"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(self.latent_dim, activation='relu'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(28*28, activation='sigmoid'),\n",
    "            layers.Reshape((28, 28))\n",
    "        ])\n",
    "    \n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "latent_dim = 64\n",
    "autoencoder = Autoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, latent_dim=32, name=\"encoder\", **kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dense = layers.Dense(self.latent_dim, activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = layers.Flatten()(inputs)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "    \"\"\"Converts z, the encoded digit vector, back into a readable digit.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, name=\"decoder\", **kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.dense = layers.Dense(self.original_dim, activation='relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense(inputs)\n",
    "        x = layers.Reshape((28, 28))(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AutoEncoder2(tf.keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        original_dim,\n",
    "        latent_dim,\n",
    "        name=\"autoencoder\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(AutoEncoder2, self).__init__(name=name, **kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim)\n",
    "        self.decoder = Decoder(original_dim=original_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "autoencoder2 = AutoEncoder2(original_dim=28*28, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autoencoder(latent_dim, input_shape=(28, 28)):\n",
    "    inputs = tf.keras.Input(shape=input_shape, name='input')\n",
    "    # encoder\n",
    "    encoded = layers.Flatten()(inputs)\n",
    "    encoded = layers.Dense(latent_dim, activation='relu')(encoded)\n",
    "    # decoder\n",
    "    decoded = layers.Dense(np.prod(input_shape), activation='sigmoid')(encoded)\n",
    "    decoded = layers.Reshape((28, 28))(decoded)\n",
    "\n",
    "    # model\n",
    "    autoencoder = tf.keras.Model(inputs=inputs, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "autoencoder = get_autoencoder(latent_dim, input_shape=(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oJSeMTroABs"
   },
   "source": [
    "Train the model using `x_train` as both the input and the target. The `encoder` will learn to compress the dataset from `latent_dim` dimensions to the latent space, and the `decoder` will learn to reconstruct the original images.\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:23:35.341976Z",
     "iopub.status.busy": "2021-01-13T02:23:35.339844Z",
     "iopub.status.idle": "2021-01-13T02:24:04.874837Z",
     "shell.execute_reply": "2021-01-13T02:24:04.875310Z"
    },
    "id": "h1RI9OfHDBsK"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the `test_mse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = autoencoder.evaluate(x_test, x_test)\n",
    "print('MSE Test:', test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAM1QBhtoC-n"
   },
   "source": [
    "Now that the model is trained, let's test it by encoding and decoding images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.899566Z",
     "iopub.status.busy": "2021-01-13T02:24:04.898808Z",
     "iopub.status.idle": "2021-01-13T02:24:04.948566Z",
     "shell.execute_reply": "2021-01-13T02:24:04.947854Z"
    },
    "id": "Pbr5WCj7FQUi"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.969875Z",
     "iopub.status.busy": "2021-01-13T02:24:04.967986Z",
     "iopub.status.idle": "2021-01-13T02:24:05.903930Z",
     "shell.execute_reply": "2021-01-13T02:24:05.904391Z"
    },
    "id": "s4LlDOS6FUA1"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent_dim in [16, 32, 64, 128, 256, 512, 784]:\n",
    "    t = time.time()\n",
    "    autoencoder = get_autoencoder(latent_dim, input_shape=(28, 28))\n",
    "    autoencoder.fit(x_train, x_train, epochs=7, batch_size=64, verbose=0)\n",
    "    test_mse = autoencoder.evaluate(x_test, x_test, verbose=0)\n",
    "    elapsed_time = time.time() - t\n",
    "    print('#' * 100)\n",
    "    print('Latent dimension: {0}, MSE Test: {1}, elapsed time: {2}'.format(\n",
    "        latent_dim, test_mse, elapsed_time))\n",
    "    n = 10\n",
    "    reconstructed = autoencoder(x_test).numpy()\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i])\n",
    "        plt.title(\"original\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(reconstructed[i])\n",
    "        plt.title(\"reconstructed\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add more complexity to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "def get_autoencoder(latent_dim, input_shape=(28, 28)):\n",
    "    inputs = tf.keras.Input(shape=input_shape, name='input')\n",
    "    # encoder\n",
    "    encoded = layers.Flatten()(inputs)\n",
    "    encoded = layers.Dense(2 * latent_dim, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(latent_dim, activation='relu')(encoded)\n",
    "    # decoder\n",
    "    decoded = layers.Dense(2 * latent_dim, activation='relu')(encoded)\n",
    "    decoded = layers.Dense(np.prod(input_shape), activation='sigmoid')(encoded)\n",
    "    decoded = layers.Reshape((28, 28))(decoded)\n",
    "\n",
    "    # model\n",
    "    autoencoder = tf.keras.Model(inputs=inputs, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "latent_dim = 128\n",
    "autoencoder = get_autoencoder(latent_dim, input_shape=(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = autoencoder.evaluate(x_test, x_test)\n",
    "print('MSE Test:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.899566Z",
     "iopub.status.busy": "2021-01-13T02:24:04.898808Z",
     "iopub.status.idle": "2021-01-13T02:24:04.948566Z",
     "shell.execute_reply": "2021-01-13T02:24:04.947854Z"
    },
    "id": "Pbr5WCj7FQUi"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.969875Z",
     "iopub.status.busy": "2021-01-13T02:24:04.967986Z",
     "iopub.status.idle": "2021-01-13T02:24:05.903930Z",
     "shell.execute_reply": "2021-01-13T02:24:05.904391Z"
    },
    "id": "s4LlDOS6FUA1"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Convolutional autoencoder\n",
    "\n",
    "We will use Conv2D layer for the encoder and [Transposed convolution layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) (sometimes called Deconvolution) for the decoder\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Conv2DTranspose(\n",
    "    filters, kernel_size, strides=(1, 1)\n",
    "```\n",
    "\n",
    "- **Input shape**: (batch_size, rows, cols, channels)\n",
    "\n",
    "- **Output shape**: (batch_size, new_rows, new_cols, filters)\n",
    "    - new_rows = ((rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +output_padding[0])\n",
    "    - new_cols = ((cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +output_padding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((4, 28, 28, 1))\n",
    "print('x shape: ', x.shape)\n",
    "x1 = tf.keras.layers.Conv2D(6, (3,3), padding='same')(x)\n",
    "print('x1 shape: ', x1.shape)\n",
    "x2 = tf.keras.layers.Conv2DTranspose(1, (3,3), padding='same')(x1)\n",
    "print('x2 shape: ', x2.shape)\n",
    "print('x2 shape padding valid: ', tf.keras.layers.Conv2DTranspose(1, (3,3), padding='valid')(x1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_conv_autoencoder(input_shape=(28, 28, 1)):\n",
    "    inputs = tf.keras.Input(shape=input_shape, name='input')\n",
    "    # encoder\n",
    "    encoded = layers.Conv2D(16, (3,3), strides=(2,2),activation='relu', padding='same')(inputs)\n",
    "    encoded = layers.Conv2D(16, (3,3), strides=(2,2), activation='relu', padding='same')(encoded)\n",
    "    # decoder\n",
    "    decoded = layers.Conv2DTranspose(16, kernel_size=3, strides=(2,2), activation='relu', padding='same')(encoded)\n",
    "    decoded = layers.Conv2DTranspose(16, kernel_size=3, strides=(2,2), activation='relu', padding='same')(decoded)\n",
    "    decoded = layers.Conv2DTranspose(1, kernel_size=(3,3), activation='sigmoid', padding='same')(decoded)\n",
    "\n",
    "    # model\n",
    "    autoencoder = tf.keras.Model(inputs=inputs, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = get_conv_autoencoder(input_shape=(28, 28, 1))    \n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = autoencoder.evaluate(x_test, x_test)\n",
    "print('MSE Test:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.899566Z",
     "iopub.status.busy": "2021-01-13T02:24:04.898808Z",
     "iopub.status.idle": "2021-01-13T02:24:04.948566Z",
     "shell.execute_reply": "2021-01-13T02:24:04.947854Z"
    },
    "id": "Pbr5WCj7FQUi"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.969875Z",
     "iopub.status.busy": "2021-01-13T02:24:04.967986Z",
     "iopub.status.idle": "2021-01-13T02:24:05.903930Z",
     "shell.execute_reply": "2021-01-13T02:24:05.904391Z"
    },
    "id": "s4LlDOS6FUA1"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4gv6G8PoRQE"
   },
   "source": [
    "## Image denoising\n",
    "\n",
    "\n",
    "\n",
    "An autoencoder can also be trained to remove noise from images. In the following section, you will create a noisy version of the Fashion MNIST dataset by applying random noise to each image. You will then train an autoencoder using the noisy image as input, and the original image as the target.\n",
    "\n",
    "Let's reimport the dataset to omit the modifications made earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPZl_6P65_8R"
   },
   "source": [
    "Adding random noise to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:06.436003Z",
     "iopub.status.busy": "2021-01-13T02:24:06.435271Z",
     "iopub.status.idle": "2021-01-13T02:24:06.643499Z",
     "shell.execute_reply": "2021-01-13T02:24:06.644006Z"
    },
    "id": "axSMyxC354fc"
   },
   "outputs": [],
   "source": [
    "sigma = 0.3\n",
    "x_train_noisy = x_train + sigma * tf.random.normal(shape=x_train.shape) \n",
    "x_test_noisy = x_test + sigma * tf.random.normal(shape=x_test.shape) \n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRxHe4XXltNd"
   },
   "source": [
    "Plot the noisy images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:06.665303Z",
     "iopub.status.busy": "2021-01-13T02:24:06.664572Z",
     "iopub.status.idle": "2021-01-13T02:24:07.423148Z",
     "shell.execute_reply": "2021-01-13T02:24:07.423605Z"
    },
    "id": "thKUmbVVCQpt"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = get_conv_autoencoder(input_shape=(28, 28, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = autoencoder.evaluate(x_test, x_test)\n",
    "print('MSE Test:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.899566Z",
     "iopub.status.busy": "2021-01-13T02:24:04.898808Z",
     "iopub.status.idle": "2021-01-13T02:24:04.948566Z",
     "shell.execute_reply": "2021-01-13T02:24:04.947854Z"
    },
    "id": "Pbr5WCj7FQUi"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-13T02:24:04.969875Z",
     "iopub.status.busy": "2021-01-13T02:24:04.967986Z",
     "iopub.status.idle": "2021-01-13T02:24:05.903930Z",
     "shell.execute_reply": "2021-01-13T02:24:05.904391Z"
    },
    "id": "s4LlDOS6FUA1"
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the noise during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = get_conv_autoencoder(input_shape=(28, 28, 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    print('#'*75)\n",
    "    print('epoch :', epoch)\n",
    "    x_train_noisy = x_train + sigma * tf.random.normal(shape=x_train.shape) \n",
    "    x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "    autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=1,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))\n",
    "    \n",
    "    decoded_imgs = autoencoder(x_test).numpy()\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test_noisy[i])\n",
    "        plt.title(\"original\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        plt.title(\"reconstructed\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: Create a denoising autoencoder for the flower's dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128,128)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,  # 80%  train, 20% validation\n",
    "  subset='training',  # 'training' o 'validation', only  with 'validation_split'\n",
    "  seed=1,\n",
    "  image_size=image_size,  # Dimension (img_height, img_width) for rescaling\n",
    "  batch_size=64\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset='validation',\n",
    "  seed=1,\n",
    "  image_size=image_size,\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(x_in, sigma=0.2):\n",
    "    x = x_in / 255\n",
    "    x_noisy = x + sigma * tf.random.normal(shape=tf.shape(x))\n",
    "    x_noisy = tf.clip_by_value(x_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "    return (x_noisy, x)\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: prepare_dataset(x))\n",
    "val_ds = val_ds.map(lambda x, y: prepare_dataset(x))\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_noisy, x in val_ds.take(1):\n",
    "    n = 5\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x[i])\n",
    "        plt.title(\"original\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(x_noisy[i])\n",
    "        plt.title(\"noisy\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_autoencoder(input_shape=(28, 28, 1)):\n",
    "    inputs = tf.keras.Input(shape=input_shape, name='input')\n",
    "    # encoder\n",
    "    ...\n",
    "    # model\n",
    "    autoencoder = tf.keras.Model(inputs=inputs, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = get_conv_autoencoder(input_shape=(128,128,3))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    print('#' * 60)\n",
    "    print('epoch', epoch)\n",
    "    autoencoder.fit(train_ds,\n",
    "                    epochs=1,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=10)\n",
    "    for x_noisy, x in val_ds.take(1):\n",
    "        decoded_imgs = autoencoder(x_noisy).numpy()\n",
    "        n = 5\n",
    "        plt.figure(figsize=(22, 10))\n",
    "        for i in range(n):\n",
    "            # display original\n",
    "            ax = plt.subplot(2, n, i + 1)\n",
    "            plt.imshow(x_noisy[i])\n",
    "            plt.title(\"original\")\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "            # display reconstruction\n",
    "            ax = plt.subplot(2, n, i + 1 + n)\n",
    "            plt.imshow(decoded_imgs[i])\n",
    "            plt.title(\"reconstructed\")\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_noisy, x in val_ds.take(1):\n",
    "    decoded_imgs = autoencoder(x_noisy).numpy()\n",
    "    n = 5\n",
    "    plt.figure(figsize=(22, 10))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_noisy[i])\n",
    "        plt.title(\"original\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        plt.title(\"reconstructed\")\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
